"""
ë¶„ì„ ì„œë¹„ìŠ¤ (ë…ë¦½ì )
ë¦¬ë·° ë¶„ì„ ì „ë‹´ (í¬ë¡¤ë§ì€ MusinsaCrawlerì— ìœ„ì„)
"""
from sqlalchemy.orm import Session
from models.analysis import Analysis
from services.musinsa_api_crawler import MusinsaCrawler
import logging

logger = logging.getLogger(__name__)


class AnalysisService:
    """ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    @staticmethod
    def create_analysis(db: Session, review_url: str) -> Analysis:
        """
        ë¶„ì„ ìš”ì²­ ìƒì„±
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            review_url: ë¶„ì„í•  ë¬´ì‹ ì‚¬ ìƒí’ˆ URL
        
        Returns:
            ìƒì„±ëœ Analysis ê°ì²´
        """
        analysis = Analysis(
            review_url=review_url,
            status='queued'
        )
        db.add(analysis)
        db.commit()
        db.refresh(analysis)
        return analysis
    
    @staticmethod
    def get_analysis(db: Session, analysis_id: int) -> Analysis:
        """ë¶„ì„ ìš”ì²­ ì¡°íšŒ"""
        return db.query(Analysis).filter(Analysis.analysis_id == analysis_id).first()
    
    @staticmethod
    def list_analyses(
        db: Session,
        status: str = None,
        skip: int = 0,
        limit: int = 10
    ) -> list:
        """ë¶„ì„ ëª©ë¡ ì¡°íšŒ"""
        query = db.query(Analysis)
        
        if status:
            query = query.filter(Analysis.status == status)
        
        analyses = query.order_by(Analysis.created_at.desc()).offset(skip).limit(limit).all()
        return [analysis.to_dict() for analysis in analyses]
    
    @staticmethod
    def update_analysis_status(
        db: Session, 
        analysis_id: int, 
        status: str,
        verdict: str = None,
        confidence: float = None,
        error_message: str = None,
        review_count: int = None
    ):
        """ë¶„ì„ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        analysis = db.query(Analysis).filter(Analysis.analysis_id == analysis_id).first()
        if analysis:
            analysis.status = status
            if verdict:
                analysis.verdict = verdict
            if confidence is not None:
                analysis.confidence = confidence
            if error_message:
                analysis.error_message = error_message
            if review_count is not None:
                analysis.review_count = review_count
            db.commit()
            db.refresh(analysis)
        return analysis
    
    @staticmethod
    async def analyze_with_ai(reviews: list, analysis_id: int, db: Session) -> dict:
        """
        AI ì„œë²„ë¡œ ë¦¬ë·° ë¶„ì„ ìš”ì²­
        
        ì›¹ì„œë²„ì—ì„œ AI Python ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Args:
            reviews: í•„í„°ë§ëœ ë¦¬ë·° ë¦¬ìŠ¤íŠ¸
            analysis_id: ë¶„ì„ ID
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        
        Returns:
            ë¶„ì„ ê²°ê³¼
        """
        try:
            logger.info(f"[Analysis {analysis_id}] ========================================")
            logger.info(f"[Analysis {analysis_id}] ğŸ¤– AI ë¶„ì„ ì‹œì‘")
            logger.info(f"[Analysis {analysis_id}] ========================================")
            logger.info(f"[Analysis {analysis_id}] ğŸ“Š ë¦¬ë·° ê°œìˆ˜: {len(reviews)}ê°œ")
            
            # === AI ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ (subprocess) ===
            import subprocess
            import json
            
            # 1. ì…ë ¥ ë°ì´í„° ì¤€ë¹„
            logger.info(f"[Analysis {analysis_id}] ğŸ“ Step 1: ì…ë ¥ ë°ì´í„° ì¤€ë¹„")
            input_data = {
                'reviews': reviews,
                'analysis_id': analysis_id
            }
            input_json = json.dumps(input_data, ensure_ascii=False)
            logger.info(f"[Analysis {analysis_id}] âœ… ì…ë ¥ ë°ì´í„° í¬ê¸°: {len(input_json)} bytes")
            
            # ìƒ˜í”Œ ë¦¬ë·° ì¶œë ¥
            if reviews:
                logger.info(f"[Analysis {analysis_id}] ğŸ“„ ì²« ë²ˆì§¸ ë¦¬ë·° ìƒ˜í”Œ: {reviews[0].get('text', '')[:50]}...")
            
            # 2. AI ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
            logger.info(f"[Analysis {analysis_id}] ğŸš€ Step 2: AI ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘...")
            logger.info(f"[Analysis {analysis_id}] ëª…ë ¹: python services/ai_analyzer.py")
            
            import time
            start_time = time.time()
            
            process = subprocess.run(
                ['python', 'services/ai_analyzer.py'],
                input=input_json,
                capture_output=True,
                text=True,
                timeout=120,  # ìµœëŒ€ 2ë¶„
                bufsize=1
            )
            
            elapsed_time = time.time() - start_time
            logger.info(f"[Analysis {analysis_id}] â±ï¸  ì‹¤í–‰ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
            
            # 3. subprocess ê²°ê³¼ ë¡œê¹…
            logger.info(f"[Analysis {analysis_id}] ğŸ“‹ Step 3: AI ìŠ¤í¬ë¦½íŠ¸ ì¶œë ¥ í™•ì¸")
            logger.info(f"[Analysis {analysis_id}] Return Code: {process.returncode}")
            
            if process.stdout:
                logger.info(f"[Analysis {analysis_id}] ===== AI ìŠ¤í¬ë¦½íŠ¸ STDOUT =====")
                for line in process.stdout.split('\n')[:20]:  # ìµœëŒ€ 20ì¤„
                    if line.strip():
                        logger.info(f"[Analysis {analysis_id}] {line}")
                logger.info(f"[Analysis {analysis_id}] ================================")
            
            if process.stderr:
                logger.warning(f"[Analysis {analysis_id}] ===== AI ìŠ¤í¬ë¦½íŠ¸ STDERR =====")
                for line in process.stderr.split('\n')[:20]:  # ìµœëŒ€ 20ì¤„
                    if line.strip():
                        logger.warning(f"[Analysis {analysis_id}] {line}")
                logger.warning(f"[Analysis {analysis_id}] ================================")
            
            # 4. ê²°ê³¼ íŒŒì‹±
            if process.returncode != 0:
                logger.error(f"[Analysis {analysis_id}] âŒ AI ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨!")
                logger.error(f"[Analysis {analysis_id}] ì—ëŸ¬: {process.stderr}")
                raise Exception(f"AI ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {process.stderr}")
            
            logger.info(f"[Analysis {analysis_id}] ğŸ” Step 4: JSON íŒŒì‹±")
            output_data = json.loads(process.stdout)
            logger.info(f"[Analysis {analysis_id}] âœ… JSON íŒŒì‹± ì„±ê³µ")
            
            if not output_data.get('success'):
                error_msg = output_data.get('error', 'AI ë¶„ì„ ì‹¤íŒ¨')
                logger.error(f"[Analysis {analysis_id}] âŒ AI ë¶„ì„ ì‹¤íŒ¨: {error_msg}")
                raise Exception(error_msg)
            
            ai_result = output_data['result']
            
            # 5. ê²°ê³¼ ì¶”ì¶œ
            logger.info(f"[Analysis {analysis_id}] ğŸ“Š Step 5: ê²°ê³¼ ì¶”ì¶œ")
            verdict = ai_result.get('verdict')
            confidence = ai_result.get('confidence', 0)
            details = ai_result.get('details', {})
            
            logger.info(f"[Analysis {analysis_id}] ========================================")
            logger.info(f"[Analysis {analysis_id}] ğŸ¯ AI ë¶„ì„ ê²°ê³¼")
            logger.info(f"[Analysis {analysis_id}] ========================================")
            logger.info(f"[Analysis {analysis_id}] íŒì •: {verdict}")
            logger.info(f"[Analysis {analysis_id}] ì‹ ë¢°ë„: {confidence}%")
            
            if details:
                logger.info(f"[Analysis {analysis_id}] ì„¸ë¶€ ì •ë³´:")
                for key, value in details.items():
                    logger.info(f"[Analysis {analysis_id}]   - {key}: {value}")
            
            result = {
                'success': True,
                'verdict': verdict,
                'confidence': confidence,
                'details': details,
                'message': 'AI ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'
            }
            
            # 6. ë¶„ì„ ì™„ë£Œ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
            logger.info(f"[Analysis {analysis_id}] ğŸ’¾ Step 6: DB ì—…ë°ì´íŠ¸")
            AnalysisService.update_analysis_status(
                db, analysis_id, 'completed',
                verdict=result['verdict'],
                confidence=result['confidence'],
                review_count=len(reviews)
            )
            
            logger.info(f"[Analysis {analysis_id}] ========================================")
            logger.info(f"[Analysis {analysis_id}] âœ… AI ë¶„ì„ ì™„ë£Œ!")
            logger.info(f"[Analysis {analysis_id}] ========================================")
            
            return result
            
        except subprocess.TimeoutExpired:
            logger.error(f"[Analysis {analysis_id}] ========================================")
            logger.error(f"[Analysis {analysis_id}] â±ï¸  AI ë¶„ì„ íƒ€ì„ì•„ì›ƒ (2ë¶„ ì´ˆê³¼)")
            logger.error(f"[Analysis {analysis_id}] ========================================")
            AnalysisService.update_analysis_status(
                db, analysis_id, 'failed',
                error_message='AI ë¶„ì„ ì‹œê°„ ì´ˆê³¼ (2ë¶„)'
            )
            return {
                'success': False,
                'message': 'AI ë¶„ì„ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.'
            }
            
        except Exception as e:
            logger.error(f"[Analysis {analysis_id}] ========================================")
            logger.error(f"[Analysis {analysis_id}] âŒ AI ë¶„ì„ ì˜¤ë¥˜")
            logger.error(f"[Analysis {analysis_id}] ========================================")
            logger.error(f"[Analysis {analysis_id}] ì—ëŸ¬ ë©”ì‹œì§€: {str(e)}")
            
            import traceback
            logger.error(f"[Analysis {analysis_id}] ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:")
            for line in traceback.format_exc().split('\n'):
                if line.strip():
                    logger.error(f"[Analysis {analysis_id}] {line}")
            
            AnalysisService.update_analysis_status(
                db, analysis_id, 'failed',
                error_message=f'AI ë¶„ì„ ì˜¤ë¥˜: {str(e)}'
            )
            return {
                'success': False,
                'message': f'AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
            }
    
    @staticmethod
    async def process_analysis(analysis_id: int, review_url: str, db: Session) -> dict:
        """
        ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        1. ë¦¬ë·° í¬ë¡¤ë§ (CrawlingServiceì— ìœ„ì„)
        2. AI ë¶„ì„
        3. ê²°ê³¼ ì €ì¥
        
        Args:
            analysis_id: ë¶„ì„ ID
            review_url: ë¬´ì‹ ì‚¬ ìƒí’ˆ URL
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        
        Returns:
            ìµœì¢… ë¶„ì„ ê²°ê³¼
        """
        try:
            logger.info(f"")
            logger.info(f"{'='*70}")
            logger.info(f"[Analysis {analysis_id}] ğŸš€ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
            logger.info(f"{'='*70}")
            logger.info(f"[Analysis {analysis_id}] URL: {review_url}")
            
            # 1. ìƒíƒœ ì—…ë°ì´íŠ¸: processing
            logger.info(f"[Analysis {analysis_id}] ğŸ“ ìƒíƒœ: queued â†’ processing")
            AnalysisService.update_analysis_status(db, analysis_id, 'processing')
            
            # 2. í¬ë¡¤ë§ (MusinsaCrawlerì— ìœ„ì„)
            logger.info(f"")
            logger.info(f"[Analysis {analysis_id}] â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            logger.info(f"[Analysis {analysis_id}] ğŸ•·ï¸  Step 1/3: ë¦¬ë·° í¬ë¡¤ë§")
            logger.info(f"[Analysis {analysis_id}] â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            
            import time
            crawl_start = time.time()
            
            crawler = MusinsaCrawler()
            crawl_result = crawler.crawl_reviews(
                product_url=review_url,
                max_reviews=100,  # ì„¤ì • ê°€ëŠ¥
                #save_to_db=True,  # DBì— ì €ì¥
                #db=db
            )
            
            crawl_time = time.time() - crawl_start
            
            if not crawl_result['success']:
                logger.error(f"[Analysis {analysis_id}] âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {crawl_result['message']}")
                AnalysisService.update_analysis_status(
                    db, analysis_id, 'failed',
                    error_message=crawl_result['message']
                )
                return {
                    'success': False,
                    'message': crawl_result['message'],
                    'analysis_id': analysis_id,
                    'status': 'failed'
                }
            
            logger.info(f"[Analysis {analysis_id}] âœ… í¬ë¡¤ë§ ì™„ë£Œ!")
            logger.info(f"[Analysis {analysis_id}] â±ï¸  ì†Œìš” ì‹œê°„: {crawl_time:.2f}ì´ˆ")
            logger.info(f"[Analysis {analysis_id}] ğŸ“Š ìˆ˜ì§‘ëœ ë¦¬ë·°: {crawl_result['raw_count']}ê°œ")
            logger.info(f"[Analysis {analysis_id}] ğŸ¯ í•„í„°ë§ëœ ë¦¬ë·°: {crawl_result['filtered_count']}ê°œ")
            
            if crawl_result['filtered_count'] == 0:
                logger.warning(f"[Analysis {analysis_id}] âš ï¸  ë¶„ì„í•  ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤")
                AnalysisService.update_analysis_status(
                    db, analysis_id, 'failed',
                    error_message='ë¶„ì„í•  ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤'
                )
                return {
                    'success': False,
                    'message': 'ë¶„ì„í•  ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤',
                    'analysis_id': analysis_id,
                    'status': 'failed'
                }
            
            # 3. AI ë¶„ì„
            logger.info(f"")
            logger.info(f"[Analysis {analysis_id}] â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            logger.info(f"[Analysis {analysis_id}] ğŸ¤– Step 2/3: AI ë¶„ì„")
            logger.info(f"[Analysis {analysis_id}] â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            
            ai_start = time.time()
            
            ai_result = await AnalysisService.analyze_with_ai(
                reviews=crawl_result['reviews'],
                analysis_id=analysis_id,
                db=db
            )
            
            ai_time = time.time() - ai_start
            logger.info(f"[Analysis {analysis_id}] â±ï¸  AI ë¶„ì„ ì†Œìš” ì‹œê°„: {ai_time:.2f}ì´ˆ")
            
            if not ai_result['success']:
                logger.error(f"[Analysis {analysis_id}] âŒ AI ë¶„ì„ ì‹¤íŒ¨")
                return {
                    'success': False,
                    'message': ai_result['message'],
                    'analysis_id': analysis_id,
                    'status': 'failed'
                }
            
            # 4. ìµœì¢… ê²°ê³¼ ë°˜í™˜
            logger.info(f"")
            logger.info(f"[Analysis {analysis_id}] â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            logger.info(f"[Analysis {analysis_id}] ğŸ’¾ Step 3/3: ê²°ê³¼ ì €ì¥ ë° ì™„ë£Œ")
            logger.info(f"[Analysis {analysis_id}] â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            
            analysis = AnalysisService.get_analysis(db, analysis_id)
            
            total_time = crawl_time + ai_time
            
            logger.info(f"")
            logger.info(f"{'='*70}")
            logger.info(f"[Analysis {analysis_id}] ğŸ‰ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            logger.info(f"{'='*70}")
            logger.info(f"[Analysis {analysis_id}] ğŸ“Š ìµœì¢… ê²°ê³¼:")
            logger.info(f"[Analysis {analysis_id}]   - íŒì •: {analysis.verdict}")
            logger.info(f"[Analysis {analysis_id}]   - ì‹ ë¢°ë„: {analysis.confidence}%")
            logger.info(f"[Analysis {analysis_id}]   - ë¦¬ë·° ìˆ˜: {analysis.review_count}ê°œ")
            logger.info(f"[Analysis {analysis_id}]   - ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
            logger.info(f"{'='*70}")
            logger.info(f"")
            
            return {
                'success': True,
                'message': 'ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
                'analysis_id': analysis.analysis_id,
                'status': analysis.status,
                'verdict': analysis.verdict,
                'confidence': float(analysis.confidence) if analysis.confidence else None,
                'review_count': analysis.review_count
            }
            
        except Exception as e:
            logger.error(f"")
            logger.error(f"{'='*70}")
            logger.error(f"[Analysis {analysis_id}] âŒ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜")
            logger.error(f"{'='*70}")
            logger.error(f"[Analysis {analysis_id}] ì—ëŸ¬: {str(e)}")
            
            import traceback
            logger.error(f"[Analysis {analysis_id}] ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:")
            for line in traceback.format_exc().split('\n'):
                if line.strip():
                    logger.error(f"[Analysis {analysis_id}] {line}")
            logger.error(f"{'='*70}")
            logger.error(f"")
            
            AnalysisService.update_analysis_status(
                db, analysis_id, 'failed',
                error_message=str(e)
            )
            return {
                'success': False,
                'message': f'ë¶„ì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}',
                'analysis_id': analysis_id,
                'status': 'failed'
            }